{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ukbang/Build_with_AI_2025/blob/main/1_DataAgent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langgraph langchain-google-genai langchain-core langchain-community langchain-experimental koreanize-matplotlib"
      ],
      "metadata": {
        "id": "a8CFmevINixl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-openai"
      ],
      "metadata": {
        "id": "lm0tn2hPrARy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3Fb0LGFNAyX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import koreanize_matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from typing import Annotated, Literal, Tuple\n",
        "from typing_extensions import TypedDict\n",
        "from langchain.schema import AIMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from langchain_experimental.tools.python.tool import PythonAstREPLTool\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "import base64\n",
        "import io\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google_api_key = \"\" # @param {\"type\":\"string\"}\n",
        "openai_api_key = \"\" # @param {\"type\":\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wZ2RUBbCN2NT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 환경변수에 Goolge API Key 등록\n",
        "\n",
        "os.environ[\"google_api_key\"] = google_api_key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = google_api_key\n",
        "os.environ[\"openai_api_key\"] = openai_api_key\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ],
      "metadata": {
        "id": "CEoJbMcgN8gM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터프레임 불러오기\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Ukbang/Build_with_AI_2025/main/data/titanic.csv\"\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "uC6EbKB0GP-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터프레임 정보 확인\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "id": "2neBqQJ9HJU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프 상태 정의\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages : Annotated[list, add_messages] # History\n",
        "    code : Annotated[str, \"Python code\"]\n",
        "    code_result : Annotated[str, \"Python code Result\"]"
      ],
      "metadata": {
        "id": "aaJPnfYRJUgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM 로드\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",\n",
        "                            temperature=0.,\n",
        "                            convert_system_message_to_human=True,\n",
        "                            )\n",
        "\n",
        "# llm =ChatOpenAI(model=\"gpt-4o-mini\",\n",
        "#            temperature=0.)\n",
        "\n",
        "# llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-preview-04-17\",\n",
        "#                             temperature=0.,\n",
        "#                             convert_system_message_to_human=True,\n",
        "#                             )\n",
        "\n",
        "# 파이썬 코드 실행 도구 정의\n",
        "tool = PythonAstREPLTool(name=\"python_repl_ast\",\n",
        "                        description=\"A Python shell. Use this to execute python commands. \\\n",
        "                                    Input should be a valid python command. When using this tool, \\\n",
        "                                    sometimes output is abbreviated - make sure it does not look abbreviated before using it in your answer.\",\n",
        "                         locals={\"df\":df})"
      ],
      "metadata": {
        "id": "tcmDrLQ1Z8Tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool.invoke(\"```python for i in range(10): print(i)\")"
      ],
      "metadata": {
        "id": "LdS-B6zElmuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAM2U-ftNAys"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 제목, 요약 생성 함수\n",
        "\n",
        "def create_title_summary(df:pd.DataFrame) -> Tuple[str, str]:\n",
        "\n",
        "    # 데이터셋이 너무 클 시 3000개의 샘플만 제공\n",
        "    df_sampled = df.sample(n=3000) if len(df) > 3000 else df\n",
        "\n",
        "    prompt = PromptTemplate.from_template(\"\"\"\n",
        "            당신은 요약 전문가입니다.\n",
        "\n",
        "            데이터셋 : {df}\n",
        "\n",
        "            데이터셋의 정보를 보고 제목과 요약을 만들어냅니다.\n",
        "            제목은 이 데이터셋을 가장 잘 표현할 수 있는 제목으로 결정하여야합니다.\n",
        "\n",
        "\n",
        "            제목:\n",
        "            요약:\n",
        "\n",
        "            \"\"\"\n",
        "            )\n",
        "\n",
        "    chain = prompt | llm\n",
        "\n",
        "    # chain.invoke는 AI Message객체를 반환함. 그 중 str 형태인 content만 추출\n",
        "    result = chain.invoke({\"df\":df_sampled})\n",
        "\n",
        "    title = \"Untitled\"\n",
        "    summary = \"No Summary\"\n",
        "\n",
        "    # 요약 양식에 맞지 않는 답변을 할 시 \"Untitle\"과 \"No Summary\"로 설정하도록 예외처리\n",
        "    try:\n",
        "        content = result.content\n",
        "        content = content.replace(\"## 결과:\\n\\n\", \"\")\n",
        "        lines = content.split(\"\\n\")\n",
        "        title = lines[0].replace(\"## 제목:\", \"\").strip()\n",
        "        summary = \"\\n\".join(lines[1:]).replace(\"## 요약:\", \"\").strip()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    print(\"===== 제목, 요약 생성 완료 =====\")\n",
        "\n",
        "    return title, summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 제목, 요약 생성\n",
        "\n",
        "title, summary = create_title_summary(df)"
      ],
      "metadata": {
        "id": "9Sbl3JTPVht9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"제목 : \", title)\n",
        "print(\"요약 : \", summary)"
      ],
      "metadata": {
        "id": "kj9o_tU-Vq--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM에게 도구 할당\n",
        "\n",
        "llm_with_tools = llm.bind_tools([tool])"
      ],
      "metadata": {
        "id": "-gp6Mgl7aHNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_with_tools.invoke(\"1부터 10까지  출력하는 파이썬 코드\")"
      ],
      "metadata": {
        "id": "-nxBwoZGmOPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HistoryChecker(BaseModel):\n",
        "    \"\"\"\n",
        "    이전의 대화 기록을 참고하여 질문에 대해 답변할 수 있는지 판단합니다.\n",
        "    답변할 수 있다면 \"yes\", 답변할 수 없다면 \"no\"를 반환합니다.\n",
        "    \"\"\"\n",
        "\n",
        "    yes_no : Literal[\"yes\", \"no\"] = Field(..., description=\"\"\"Use your previous conversation history to determine if you can answer your questions.\n",
        "    Return \"yes\" if you can answer, \"no\" if you can't answer.\"\"\")"
      ],
      "metadata": {
        "id": "paaE83Obacjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM의 응답을 HistoryChecker 클래스 구조에 맞춰 파싱하도록 설정\n",
        "\n",
        "history_checker = llm.with_structured_output(HistoryChecker)"
      ],
      "metadata": {
        "id": "DKyg_Geda1Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_checker.invoke(\"오늘 인천 날씨는 어때?\")"
      ],
      "metadata": {
        "id": "eqZSE35PfNbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 히스토리 기반 답변 분기를 위한 함수 설정\n",
        "\n",
        "def history_check(state:State):\n",
        "\n",
        "    prompt = PromptTemplate.from_template(\"\"\"\n",
        "\n",
        "                이전의 대화 기록을 참고하여 질문에 대해 답변할 수 있는지 판단합니다.\n",
        "                답변할 수 있다면 \"yes\", 답변할 수 없다면 \"no\"를 반환합니다.\n",
        "\n",
        "                대화 기록 : {history}\n",
        "\n",
        "                질문 : {query}\n",
        "\n",
        "                \"\"\")\n",
        "\n",
        "    chain = prompt | history_checker\n",
        "\n",
        "    result = chain.invoke({\"history\":state[\"messages\"][:-1],\n",
        "                            \"query\":state[\"messages\"][-1]})\n",
        "\n",
        "    return result.yes_no"
      ],
      "metadata": {
        "id": "QqOG4bBgbRBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 식별을 위한 노드\n",
        "\n",
        "def history_node(state:State):\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "YnhRKXIFaYMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 도구 사용 여부 결정 노드\n",
        "\n",
        "def select(state:State):\n",
        "    prompt = PromptTemplate.from_template(\"\"\"\n",
        "            당신은 데이터 분석가입니다.\n",
        "            당신은 데이터프레임인 df를 활용할 수 있습니다.\n",
        "            당신이 활용 가능한 데이터프레임의 예시는 아래와 같습니다.\n",
        "            아래의 예시는 `print(df.head())`의 실행결과입니다.\n",
        "            활용 가능한 데이터프레임을 갖고 있으니 데이터프레임을 새로 생성할 필요 없습니다.\n",
        "            코드에 한글이 필요하다면 `import koreanize_matplotlib`을 사용하세요.\n",
        "\n",
        "            당신은 'python_repl_ast'라는 파이썬 코드 실행 도구만을 가지고 있습니다.\n",
        "            아래의 내용을 참고하여 질문에 대한 코드를 생성합니다.\n",
        "\n",
        "            df : {df}\n",
        "\n",
        "            title : {title}\n",
        "            summary : {summary}\n",
        "\n",
        "            query : {query}\n",
        "            \"\"\"\n",
        "            )\n",
        "\n",
        "    chain = prompt | llm_with_tools\n",
        "\n",
        "    result = chain.invoke({\"df\":df.head(),\n",
        "                           \"title\":title,\n",
        "                            \"summary\":summary,\n",
        "                            \"query\":state[\"messages\"][-1].content})\n",
        "\n",
        "    if hasattr(result, \"tool_calls\") and len(result.tool_calls) > 0:\n",
        "        tool_calls = result.tool_calls\n",
        "\n",
        "        # 코드 추출\n",
        "        code = tool_calls[0][\"args\"][\"query\"]\n",
        "        return {\"code\": code}\n",
        "    else:\n",
        "        # 도구 사용을 안한다면 코드는 공백으로 설정\n",
        "        return {\"code\":\"\"}"
      ],
      "metadata": {
        "id": "x_uEk4JL_kbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 코드 실행 노드\n",
        "\n",
        "def code_executor(state:State):\n",
        "\n",
        "    try:\n",
        "        # 코드 실행 결과인 이미지 추출\n",
        "        if \"plt\" in state[\"code\"] or \"sns\" in state[\"code\"]:\n",
        "            save_fig = \"\"\"\n",
        "import io\n",
        "import base64\n",
        "\n",
        "buf = io.BytesIO()\n",
        "plt.savefig(buf, format=\"png\")\n",
        "buf.seek(0)\n",
        "\n",
        "encoded = base64.b64encode(buf.read()).decode(\"utf-8\")\n",
        "\n",
        "print(encoded)\n",
        "\"\"\"\n",
        "\n",
        "            execute_code = state[\"code\"] + save_fig\n",
        "\n",
        "            result = tool.invoke(execute_code)\n",
        "\n",
        "            return {\"code_result\":result}\n",
        "        # 시각화가 아닌 경우 코드만 실행\n",
        "        else:\n",
        "            result = tool.invoke(state[\"code\"])\n",
        "            return {\"code_result\":result}\n",
        "    except:\n",
        "        return {\"code_result\": \"\"}"
      ],
      "metadata": {
        "id": "6SZiw3nMJx7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 코드에 의한 답변 노드\n",
        "\n",
        "def code_response(state:State):\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"\"\"코드 : {code} \\n\n",
        "                    결과 : {code_result}\n",
        "        당신은 주어진 코드와 코드 결과를 바탕으로 질의에 대해 답변합니다.\n",
        "        절대 코드에 대해 설명하지마세요.\n",
        "        독자는 프로그래머가 아닙니다.\n",
        "        항상 출력되는 값을 기준으로 설명합니다.\n",
        "        숫자가 매우 중요합니다. 숫자에 대한 정보를 잊지 마세요.\n",
        "        데이터 분석과 관련된 코드가 입력된다면 항상 인사이트를 포함하세요. \"\"\"),\n",
        "        (\"human\", '{query}')\n",
        "    ])\n",
        "\n",
        "    chain = prompt | llm\n",
        "\n",
        "    result = chain.invoke({\"code\":state[\"code\"],\n",
        "                        \"code_result\":state[\"code_result\"],\n",
        "                        \"query\":state[\"messages\"][-1]})\n",
        "\n",
        "    return { \"messages\": result}"
      ],
      "metadata": {
        "id": "y2AxtsVAWbNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기억 및 일반 응답 노드\n",
        "\n",
        "def response(state:State):\n",
        "    prompt = PromptTemplate.from_template(\"\"\"\n",
        "\n",
        "                이전의 대화 기록을 참고하여 질문에 대해 답변하세요.\n",
        "                아래 대화 기록을 첨부합니다.\n",
        "                대화 기록을 통해 답변이 어렵다면 내부 지식을 참조하세요.\n",
        "\n",
        "                대화 기록 : {history}\n",
        "\n",
        "                질문 : {query}\n",
        "\n",
        "                \"\"\")\n",
        "\n",
        "    chain = prompt | llm\n",
        "\n",
        "    result = chain.invoke({\"history\":state[\"messages\"][:-1],\n",
        "                           \"query\":state[\"messages\"][-1]})\n",
        "\n",
        "    return {\"answer\":result.content,\n",
        "            \"messages\":result}"
      ],
      "metadata": {
        "id": "BCJXIZOKUcC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPWQZ8JkNAzE"
      },
      "outputs": [],
      "source": [
        "# 그래프 정의\n",
        "\n",
        "graph_builder = StateGraph(State)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8leI31mbNAzE"
      },
      "outputs": [],
      "source": [
        "# 노드 및 엣지 정의\n",
        "\n",
        "graph_builder.add_node(\"history_node\", history_node)\n",
        "graph_builder.add_node(\"select\", select)\n",
        "graph_builder.add_node(\"code_executor\", code_executor)\n",
        "graph_builder.add_node(\"code_response\", code_response)\n",
        "graph_builder.add_node(\"response\", response)\n",
        "\n",
        "\n",
        "graph_builder.add_edge(START, \"history_node\")\n",
        "graph_builder.add_conditional_edges(\"history_node\",\n",
        "                                    history_check,\n",
        "                                    {\n",
        "                                    \"no\":\"select\",\n",
        "                                     \"yes\":\"response\"\n",
        "                                     }\n",
        "                                     )\n",
        "graph_builder.add_edge(\"select\", \"code_executor\")\n",
        "graph_builder.add_edge(\"code_executor\", \"code_response\")\n",
        "graph_builder.add_edge(\"code_response\", END)\n",
        "graph_builder.add_edge(\"response\", END);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PA5vDSf0NAzF"
      },
      "outputs": [],
      "source": [
        "# 메모리 설정 및 그래프 컴파일\n",
        "\n",
        "memory = MemorySaver()\n",
        "\n",
        "graph = graph_builder.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUGe4U7fNAzF"
      },
      "outputs": [],
      "source": [
        "# 그래프 시각화\n",
        "# 가끔 \"ReadTimeout: HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)\"라는 에러가 발생\n",
        "# 시간 초과로 그래프 생성에 실패했다는 메시지일뿐 기능과는 관계없으니 진행해도 괜찮습니다.\n",
        "\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9n_EjPk7NAzG"
      },
      "outputs": [],
      "source": [
        "# 사용할 설정값 정의\n",
        "\n",
        "config = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": \"12\"})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력 함수 정의\n",
        "# mode = \"values\" : 상태의 키, 값의 형태로 반환\n",
        "# mode = \"updates\" : 업데이트되는 값만 반환\n",
        "\n",
        "def streaming(query, config, mode=\"values\"):\n",
        "\n",
        "    result = graph.stream({\"messages\":(\"user\", query)}, config=config, stream_mode=mode)\n",
        "\n",
        "    if mode == \"values\":\n",
        "        for step in result:\n",
        "            for k, v in step.items():\n",
        "                if k == \"messages\":\n",
        "                    v[-1].pretty_print()\n",
        "                    print(\"\\n\\n\")\n",
        "    elif mode == \"updates\":\n",
        "        for step in result:\n",
        "            for k,v in step.items():\n",
        "                print(f\"\\n\\n=== {k} ===\\n\\n\")\n",
        "                print(v)\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "WS9dgOMnYgGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "streaming(\"생존자 비율 시각화하고 인사이트 제공해줘\", config)"
      ],
      "metadata": {
        "id": "-7xAmjrxczfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "streaming(\"아까 내가 질문했던 내용 다시 알려줘\", config)"
      ],
      "metadata": {
        "id": "iArpGG4WZi7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "streaming(\"아까 물어봤던 숫자들 다 더하면 몇인지 알려줘\", config)"
      ],
      "metadata": {
        "id": "UoGSxc6weXyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUDBXiEmNAzJ"
      },
      "outputs": [],
      "source": [
        "# 올림픽 데이터 로드 및 도구 재정의\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Ukbang/Build_with_AI_2025/main/data/athlete_events.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "tool = PythonAstREPLTool(name=\"python_repl_ast\",\n",
        "                        description=\"A Python shell. Use this to execute python commands. \\\n",
        "                                    Input should be a valid python command. When using this tool, \\\n",
        "                                    sometimes output is abbreviated - make sure it does not look abbreviated before using it in your answer.\",\n",
        "                        locals={\"df\":df})\n",
        "\n",
        "\n",
        "# 제목, 요약 생성\n",
        "title, summary = create_title_summary(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAoEdavqNAzJ"
      },
      "outputs": [],
      "source": [
        "print(\"제목 : \", title)\n",
        "print()\n",
        "print(\"요약 : \", summary)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": \"99\"})\n",
        "\n",
        "streaming(\"올림픽에는 몇개의 나라가 출전했나요?\", config)"
      ],
      "metadata": {
        "id": "v6lOKJdefF-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "streaming(\"가장 많이 출전한 나라는 어디인가요?\", config)"
      ],
      "metadata": {
        "id": "iUSc9JpThD0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMha9hDYNAzR"
      },
      "outputs": [],
      "source": [
        "df[\"NOC\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLHFRDSuNAzW"
      },
      "outputs": [],
      "source": [
        "streaming(\"올림픽에 출전한 선수들의 평균 체중은 얼마인가요?\", config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrW1khQkNAzX"
      },
      "outputs": [],
      "source": [
        "df[\"Weight\"].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpC9frFaNAzZ"
      },
      "outputs": [],
      "source": [
        "config = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": \"999\"})\n",
        "\n",
        "streaming(\"키와 체중, 그리고 메달 획득과의 상관관계를 보여주세요. 산점도 그래프로 그려주세요.\", config)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Modulabs",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}